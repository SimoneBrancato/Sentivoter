services:

  abcnews:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: abcnews
    container_name: abcnews
    environment:
      - CHANNEL_ID=UCBi2mrWuNuyYy4gbM6fU18Q
      - STATE=NY
      - BIAS=LEAN_DEMOCRAT
      - YT_API_KEY=${ABC_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    command: sh -c "sleep 90s ; python3 -u script.py"

  foxnews:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: foxnews
    container_name: foxnews
    environment:
      - CHANNEL_ID=UCXIJgqnII2ZOINSWNOGFThA
      - STATE=NY
      - BIAS=REPUBLICAN
      - YT_API_KEY=${FOX_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  nbcnews:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: nbcnews
    container_name: nbcnews
    environment:
      - CHANNEL_ID=UCeY0bbntWzzVIaj2z3QigXg
      - STATE=NY
      - BIAS=LEAN_DEMOCRAT
      - YT_API_KEY=${NBC_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  cbsnews:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: cbsnews
    container_name: cbsnews
    environment:
      - CHANNEL_ID=UC8p1vwvWtl6T73JiExfWs1g
      - STATE=NY
      - BIAS=LEAN_DEMOCRAT
      - YT_API_KEY=${CBS_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  usatoday:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: usatoday
    container_name: usatoday
    environment:
      - CHANNEL_ID=UCP6HGa63sBC7-KHtkme-p-g
      - STATE=DC
      - BIAS=LEAN_DEMOCRAT
      - YT_API_KEY=${UST_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  theyoungturks:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: theyoungturks
    container_name: theyoungturks
    environment:
      - CHANNEL_ID=UC1yBKRuGpC1tSM73A0ZjYjQ
      - STATE=CA
      - BIAS=DEMOCRAT
      - YT_API_KEY=${TYT_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  goodmorningamerica:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: goodmorningamerica
    container_name: goodmorningamerica
    environment:
      - CHANNEL_ID=UCH1oRy1dINbMVp3UFWrKP0w
      - STATE=NY
      - BIAS=CENTER
      - YT_API_KEY=${GMA_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  washington_post:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: washington_post
    container_name: washington_post
    environment:
      - CHANNEL_ID=UCHd62-u_v4DvJ8TCFtpi4GA
      - STATE=DC
      - BIAS=LEAN_DEMOCRAT
      - YT_API_KEY=${WPO_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"
  
  new_york_times:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: new_york_times
    container_name: new_york_times
    environment:
      - CHANNEL_ID=UCqnbDFdCpuN8CMEg0VuEBqA
      - STATE=NY
      - BIAS=DEMOCRAT
      - YT_API_KEY=${NYT_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  the_wall_street_journal:
    build:
      context: producer/
      dockerfile: ./Dockerfile
    image: the_wall_street_journal
    container_name: the_wall_street_journal
    environment:
      - CHANNEL_ID=UCK7tptUDHh-RYDsdxO1-5QQ
      - STATE=NY
      - BIAS=REPUBLICAN
      - YT_API_KEY=${WSJ_API_KEY}
    depends_on:
      logstash:
        condition: service_healthy
      elasticsearch:
        condition: service_started
    #command: sh -c "sleep 90s ; python3 -u script.py"

  logstash:
    build: 
      context: logstash/
      dockerfile: ./Dockerfile
    container_name: logstash
    environment:
      XPACK_MONITORING_ENABLED: "false"
      pipeline.ecs_compatibility: "disabled"
      LS_JAVA_OPTS: "-Xms1g -Xmx1g"
    ports:
      - 9700:9700
    depends_on:
      - kafka
      - kafka-ui
      - elasticsearch
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:9700 || exit 1"]
      interval: 30s
      timeout: 30s
      retries: 10

  kafka:
    image: bitnami/kafka:3.7.0
    container_name: kafka
    ports:
      - 9092:9092
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:2181
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_KRAFT_CLUSTER_ID=MkU3OEVBNTcwNTJENDM2Qk
      - KAFKA_MESSAGE_MAX_BYTES=10485760
    entrypoint: /bin/bash
    command: -c "rm -rf /bitnami/kafka/data/* && /opt/bitnami/scripts/kafka/entrypoint.sh /opt/bitnami/scripts/kafka/run.sh"

  init-kafka:
    image: bitnami/kafka:3.7.0
    container_name: init-kafka
    depends_on:
      - kafka
      - kafka-ui
      - elasticsearch
    entrypoint: ['/bin/sh', '-c']
    command: |
      "
      echo 'Creating Kafka topics.'
      kafka-topics.sh --create --topic sentivoter --bootstrap-server kafka:9092 --partitions 1 --replication-factor 1 --if-not-exists
      
      echo 'Successfully updated topic list:'
      kafka-topics.sh --list --bootstrap-server kafka:9092
      "

  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    ports:
      - 8080:8080
    depends_on:
      - kafka
    environment:
      - KAFKA_CLUSTERS_0_NAME=local
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=PLAINTEXT://kafka:9092

  spark:
    build:
      context: spark/
      dockerfile: ./Dockerfile
    container_name: spark
    volumes:
      - ./spark/:/spark
      - spark_volume:/opt/spark/jars
    command: > 
      /opt/spark/bin/spark-submit --conf spark.driver.extraJavaOptions="-Divy.cache.dir=/tmp -Divy.home=/tmp" --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.elasticsearch:elasticsearch-spark-30_2.12:8.13.4  /spark/script.py
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      elasticsearch:
        condition: service_started
      abcnews:
        condition: service_started

  elasticsearch:                                        
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: elasticsearch
    volumes:
      - es_data:/usr/share/elasticsearch/data                  
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - http.port=9200
      - ES_JAVA_OPTS=-Xms4g -Xmx4g
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.7.1
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    volumes:
      - ./kibana/config:/usr/share/kibana/config
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

volumes:
  spark_volume:
  es_data: